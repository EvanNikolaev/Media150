<h1>Reading 2 reflection</h1>
<br>
<p>     In her article titled “With 'AI slop' distorting our reality, the world is sleepwalking into disaster,” Nesrine Malik argues that the prevalence of AI-generated images and videos is quietly changing the way people perceive and understand the world they live in. However, Malik’s actual worry is not only about the presence of AI content, but also about the extent of its occurrence and now its ability to confuse what is real and what is not. As an internet enthusiast, the article was alarmingly insightful for me.
    To give a background on the trends on social media, Malik uses the term “AI slop” to describe how low-quality AI images and videos are flooding social media. The significance of such images and videos is that they are realistic. What caught my attention was how Malik explained that AI does not need to be realistic to be impactful; it simply needs to be believable enough to elicit an emotional response. However, the moment people are shocked, angry, or entertained by the content, they can share it without verifying the facts. They become a part of a cycle where misinformation is being shared at a faster rate than the truth.
   Another significant aspect of Malik’s argument is the role that AI content plays in politics and the opinions of the people. In this respect, the author argues that fake content, especially images, could be used for political agendas or to create misinformation regarding the nature of real-time occurrences. This is particularly worrying because it has been argued that most people believe what they see instead of what they read. The fact that it is becoming increasingly hard for people to believe what they see, or even worse, believing what they see is the truth, shows that it is hard to have constructive discussions regarding issues that are real.
  Malik also talks about the perpetuation of social biases by AI. Since AI learns from human-made data, it picks up stereotypes related to race, gender, and culture. Instead of moving societies forward, AI slop may consolidate backwards ideas. I found this point quite convincing since it shows that AI is not impartial, but has the values and discriminatory aspects of society itself.
  The thing that struck me most about the article was Malik’s notion that people are desensitized. When tragedies and fake images coexist in cyberspace, it’s difficult to know what needs attention or what doesn’t. Ultimately, everything starts to feel sort of fake. This causes apathy—unable to care about anything because you’re overwhelmed by everything.
Overall, Malik’s article is a compelling warning about the impending dangers of turning a blind eye to the impact of AI media. She is able to illustrate that the risk is not simply technological, but also social and ethical. As a student from the generation of the digital age, I believe that Malik’s argument makes me acutely aware of the importance of being more discerning with what I see online. Without this awareness and responsibility, we run the risk of completely losing our perception of reality.






</p>
